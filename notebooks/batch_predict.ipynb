{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed dir to /Users/farooq.azam/SAP_Related_Code/predictive-ai-starter)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import datarobot as dr # type: ignore\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "# The notebook should be executed from the project root directory\n",
    "if \"_correct_path\" not in locals():\n",
    "    os.chdir(\"..\")\n",
    "    sys.path.append(\".\")\n",
    "    print(f\"changed dir to {Path('.').resolve()})\")\n",
    "    _correct_path = True\n",
    "load_dotenv()\n",
    "client = dr.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment_id: 6771ad6b20c6f3f2bdb4a217\n"
     ]
    }
   ],
   "source": [
    "import yaml # type: ignore\n",
    "with open(\"scoring_related_info.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "deployment_id = config[\"deployment_id\"]\n",
    "use_case_id = config[\"use_case_id\"]\n",
    "project_id = config[\"project_id\"]\n",
    "model_id = config[\"model_id\"]\n",
    "print(f\"deployment_id: {deployment_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_run_timestamp=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"current_run_timestamp: {current_run_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_case=dr.UseCase.get(use_case_id)\n",
    "project = use_case.list_projects()[0]\n",
    "project_feature_lists = project.get_featurelists()\n",
    "primary_feature_list = [ flist for flist in project_feature_lists if flist.name.find(\"known\") != -1][0]\n",
    "primary_feature_list_id = primary_feature_list.id\n",
    "print(f\"Primary feature list ID: {primary_feature_list_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_dataset = dr.Dataset.get('674a33cb5fb3881089667ad7')\n",
    "model = dr.Model.get(project= project, model_id=model_id)\n",
    "self_join_secondary_predict_dataset = dr.models.secondary_dataset.SecondaryDataset(\n",
    "    catalog_id=secondary_dataset.id,\n",
    "    catalog_version_id=secondary_dataset.version_id,  # Complete version lineage for predictions\n",
    "    identifier=\"CUSTOMER_DATASET\",\n",
    "    snapshot_policy=\"latest\",  # Fetch the latest database records\n",
    ")\n",
    "self_join_secondary_predict_dataset.to_dict()\n",
    "\n",
    "# Create a prediction config with the original profile dataset (static) , and a \"new\" transactions prediction dataset\n",
    "\n",
    "predict_config = dr.SecondaryDatasetConfigurations.create(\n",
    "    project_id=project.id,\n",
    "    name=\"Batch Prediction Configuration\",\n",
    "    featurelist_id=model.featurelist_id,\n",
    "    secondary_datasets=[\n",
    "        self_join_secondary_predict_dataset.to_dict(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(deployment_id)\n",
    "data_stores = dr.DataStore.list(typ='all')\n",
    "str_data_stores = [str(data_store) for data_store in data_stores]\n",
    "index = str_data_stores.index(\"DataStore(\\'DR_SAP_TEMPLATES_ALTERNATE\\')\")\n",
    "dsp_data_alternate_store= data_stores[index]\n",
    "creds = dr.Credential.list()\n",
    "str_cred_names = [str(cred.name) for cred in creds]\n",
    "index = str_cred_names.index(\"DR_SAP_TEMPLATE_CRED\")\n",
    "dsp_cred = creds[index]\n",
    "\n",
    "dataset_id = '674a33ca3e42ee7f62667a8e'\n",
    "scoring_dataset = dr.Dataset.get(dataset_id)\n",
    "batch_prediction_job_config={\n",
    "    \"deploymentId\": deployment_id,\n",
    "    \"num_concurrent\": 4,\n",
    "    \"intake_settings\":\n",
    "        {\n",
    "        'type': 'dataset',\n",
    "        'datasetId': dataset_id, \n",
    "        },\n",
    "    \"passthrough_columns\": \n",
    "        ['CUSTOMER_NUMBER', 'NET_PAYMENT_TERMS_PERIOD', 'Days_Late',\n",
    "        'INVOICE_DUE_DATE', 'ORDER_DATE', 'CASH_DISCOUNT_DAYS_2',\n",
    "        'Invoice_Due_Date_Year_Month', 'STATUS_MANUAL_PRICE_CHANGE',\n",
    "        'INVOICE_NUMBER', 'CASH_DISCOUNT_DAYS_1', 'NET_VALUE_OF_ITEM',\n",
    "        'CASH_DISCOUNT_AMOUNT', 'ITEM_CREDIT_PRICE', 'PAYMENT_TERM',\n",
    "        'MATERIAL_NAME', 'AMT_ELIGIBLE_FOR_CASH_DISCOUNT',\n",
    "        'ITEM_CREDIT_PRICE_ROUNDED', 'BASELINE_DT_FOR_DUE_DATE_CALC',\n",
    "        'MATERIAL_NUMBER', 'CASH_DISCOUNT_PERCENTAGE_2',\n",
    "        'ACTUAL_INVOICED_QUANTITY_CASES', 'Payment_Status',\n",
    "        'INVOICE_TO_PAID_DAYS', 'EXPECTED_AMOUNT', 'CUSTOMER_NAME',\n",
    "        'CASH_DISCOUNT_PERCENTAGE_1', 'SHIP_DATE', 'Days_to_Ship',\n",
    "        'ORDER_TO_PAID_DAYS', 'ACTUAL_PAID_DATE'\n",
    "        ],\n",
    "    \"output_settings\":\n",
    "        {\n",
    "        'type': 'jdbc',\n",
    "        'table': \"PREDICTION_RESULTS_SAP_TEMPLATE_{{ current_run_timestamp }}\",\n",
    "        'schema': 'DR_SAP_TEMPLATES#TEMPLATE_DB_USER', \n",
    "        'statement_type': 'create_table',\n",
    "        'data_store_id': dsp_data_alternate_store.id,\n",
    "        'credential_id': dsp_cred.credential_id,\n",
    "        },\n",
    "}\n",
    "batch_prediction_job_schedule = {\n",
    "    \"day_of_week\": [1],\n",
    "    \"month\": [\"*\"],\n",
    "    \"hour\": [16],\n",
    "    \"minute\": [0],\n",
    "    \"day_of_month\": [1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobotx.idp.batch_predictions import get_update_or_create_batch_prediction_job # type: ignore\n",
    "from infra.settings_main import project_name\n",
    "batch_prediction_job=get_update_or_create_batch_prediction_job(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    deployment_id=deployment_id,\n",
    "    enabled=True,\n",
    "    name= f\"Recipe Template Batch Prediction [{project_name}]\",\n",
    "    batch_prediction_job=batch_prediction_job_config,\n",
    "    schedule=batch_prediction_job_schedule,\n",
    "    \n",
    ")\n",
    "print(f\"batch_prediction_job: {batch_prediction_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"batch_prediction_job: {batch_prediction_job}\")\n",
    "prediction_job_definition=dr.BatchPredictionJobDefinition.get(batch_prediction_job)\n",
    "job = prediction_job_definition.run_once()\n",
    "job.wait_for_completion()\n",
    "print(f\"Batch prediction job completed with status: {job.status}\")\n",
    "print(f\"Batch predictions written to table: {batch_prediction_job_config['output_settings']['table']}\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
