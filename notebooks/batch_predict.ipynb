{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed dir to /Users/farooq.azam/SAP_Related_Code/predictive-ai-starter)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import datarobot as dr # type: ignore\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "# The notebook should be executed from the project root directory\n",
    "if \"_correct_path\" not in locals():\n",
    "    os.chdir(\"..\")\n",
    "    sys.path.append(\".\")\n",
    "    print(f\"changed dir to {Path('.').resolve()})\")\n",
    "    _correct_path = True\n",
    "load_dotenv()\n",
    "client = dr.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment_id: 6771ad6b20c6f3f2bdb4a217\n"
     ]
    }
   ],
   "source": [
    "import yaml # type: ignore\n",
    "with open(\"scoring_related_info.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "deployment_id = config[\"deployment_id\"]\n",
    "use_case_id = config[\"use_case_id\"]\n",
    "project_id = config[\"project_id\"]\n",
    "model_id = config[\"model_id\"]\n",
    "print(f\"deployment_id: {deployment_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_run_timestamp=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"current_run_timestamp: {current_run_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case=dr.UseCase.get(use_case_id)\n",
    "project = use_case.list_projects()[0]\n",
    "project_feature_lists = project.get_featurelists()\n",
    "primary_feature_list = [ flist for flist in project_feature_lists if flist.name.find(\"known\") != -1][0]\n",
    "primary_feature_list_id = primary_feature_list.id\n",
    "print(f\"Primary feature list ID: {primary_feature_list_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP Credentials ID - 6747707642a92d74cd796960\n",
      "SAP Credentials - Credential('6747707642a92d74cd796960', 'DR_SAP_TEMPLATE_CRED', 'basic')\n",
      "SAP Datastore ID - 676c46ce57b0ab717e45149a\n",
      "SAP Datastore - DataStore('DR_SAP_TEMPLATE [72d5954]')\n",
      "SAP Datasource ID - 676c46d257b0ab717e45149b\n",
      "SAP Datasource - DataSource('LATE_PAYMENTS_TRAINING_DATA_DSP [4f747c4]')\n",
      "SAP Training data set ID - 676cad9bfc42109cd1340d6c\n",
      "SAP Training data set - Dataset(name='DRS_LATE_PAYMENTS_TRAINING_DATA_VIEW_DSP [3092c80]', id='676cad9bfc42109cd1340d6c')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # type: ignore\n",
    "from infra.settings_datasets import training_dataset\n",
    "from datarobotx.idp.datasets import get_or_create_dataset_from_datasource # type: ignore\n",
    "from datarobotx.idp.datasource import get_or_create_datasource # type: ignore\n",
    "from datarobotx.idp.datastore import get_or_create_datastore # type: ignore\n",
    "from datarobotx.idp.credentials import get_replace_or_create_credential # type: ignore\n",
    "\n",
    "\n",
    "sap_dsp_data_store_canonical_name=os.getenv(\"SAP_DSP_DATA_STORE_CANONICAL_NAME\")\n",
    "sap_dsp_host_name=os.getenv(\"SAP_DSP_HOST_NAME\")\n",
    "sap_dsp_port=os.getenv(\"SAP_DSP_PORT\")\n",
    "sap_dsp_data_source=os.getenv(\"SAP_DSP_DATA_SOURCE\") \n",
    "sap_dsp_scoring_primary_data_query=os.getenv(\"SAP_DSP_LATE_PAYMENTS_PRIMARY_SCORING_DATA_QUERY\")\n",
    "sap_dsp_scoring_primary_data_set=os.getenv(\"SAP_DSP_LATE_PAYMENTS_HOLDOUT_PRIMARY_DATA_SET\")\n",
    "sap_dsp_scoring_secondary_data_query=os.getenv(\"SAP_DSP_LATE_PAYMENTS_SECONDARY_SCORING_DATA_QUERY\")\n",
    "sap_dsp_scoring_secondary_data_set=os.getenv(\"SAP_DSP_LATE_PAYMENTS_HOLDOUT_SECONDARY_DATA_SET\")\n",
    "sap_dsp_credentials=os.getenv(\"SAP_DSP_CREDENTIALS\")\n",
    "\n",
    "sap_dsp_credentials_id = get_replace_or_create_credential(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    name=sap_dsp_credentials,\n",
    "    credential_type=\"basic\",\n",
    ")\n",
    "print(f\"SAP Credentials ID - {sap_dsp_credentials_id}\")\n",
    "sap_dsp_credentials = dr.Credential.get(sap_dsp_credentials_id)\n",
    "print(f\"SAP Credentials - {sap_dsp_credentials}\")\n",
    "sap_dsp_data_store_id=get_or_create_datastore(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    canonical_name=sap_dsp_data_store_canonical_name,\n",
    "    driver_id='66c8ecdd45d2b5465fd74b49',\n",
    "    data_store_type='dr-database-v1',\n",
    "    fields=[{\"id\":\"host\",\"name\":\"Host Name\",\"value\":sap_dsp_host_name},{\"id\":\"port\",\"name\":\"port\",\"value\":sap_dsp_port}],\n",
    ")\n",
    "sap_dsp_data_store=dr.DataStore.get(sap_dsp_data_store_id)\n",
    "print(f\"SAP Datastore ID - {sap_dsp_data_store_id}\")\n",
    "print(f\"SAP Datastore - {sap_dsp_data_store}\")\n",
    "params = dr.DataSourceParameters(\n",
    "    data_store_id=sap_dsp_data_store.id,\n",
    "    query=sap_dsp_scoring_primary_data_query,\n",
    ")\n",
    "sap_dsp_data_source_id = get_or_create_datasource(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    data_source_type='dr-database-v1', \n",
    "    canonical_name=sap_dsp_data_source,\n",
    "    params=params\n",
    ")\n",
    "print(f\"SAP Datasource ID - {sap_dsp_data_source_id}\")\n",
    "print(f\"SAP Datasource - {dr.DataSource.get(sap_dsp_data_source_id)}\")\n",
    "primary_scoring_dataset_id=get_or_create_dataset_from_datasource(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    data_source_id=sap_dsp_data_source_id,\n",
    "    name=sap_dsp_scoring_primary_data_set,\n",
    "    credential_id=sap_dsp_credentials.credential_id\n",
    ")\n",
    "print(f\"SAP primary scoring data set ID - {primary_scoring_dataset_id}\")\n",
    "print(f\"SAP primary scoring data set - {dr.Dataset.get(primary_scoring_dataset_id)}\")\n",
    "params = dr.DataSourceParameters(\n",
    "    data_store_id=sap_dsp_data_store.id,\n",
    "    query=sap_dsp_scoring_secondary_data_query,\n",
    ")\n",
    "sap_dsp_data_source_id = get_or_create_datasource(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    data_source_type='dr-database-v1', \n",
    "    canonical_name=sap_dsp_data_source,\n",
    "    params=params\n",
    ")\n",
    "secondary_scoring_dataset_id=get_or_create_dataset_from_datasource(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    data_source_id=sap_dsp_data_source_id,\n",
    "    name=sap_dsp_scoring_secondary_data_set,\n",
    "    credential_id=sap_dsp_credentials.credential_id\n",
    ")\n",
    "print(f\"SAP secondary scoring data set ID - {secondary_scoring_dataset_id}\")\n",
    "print(f\"SAP secondary scoring data set - {dr.Dataset.get(secondary_scoring_dataset_id)}\")\n",
    "primary_scoring_dataset=dr.Dataset.get(primary_scoring_dataset_id)\n",
    "primary_scoring_dataset_id=primary_scoring_dataset.id\n",
    "secondary_scoring_dataset=dr.Dataset.get(secondary_scoring_dataset_id)\n",
    "secondary_scoring_dataset_id=secondary_scoring_dataset.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary_scoring_dataset = dr.Dataset.get('674a33cb5fb3881089667ad7')\n",
    "model = dr.Model.get(project= project, model_id=model_id)\n",
    "self_join_secondary_predict_dataset = dr.models.secondary_dataset.SecondaryDataset(\n",
    "    catalog_id=secondary_scoring_dataset.id,\n",
    "    catalog_version_id=secondary_scoring_dataset.version_id,  # Complete version lineage for predictions\n",
    "    identifier=\"CUSTOMER_DATASET\",\n",
    "    snapshot_policy=\"latest\",  # Fetch the latest database records\n",
    ")\n",
    "self_join_secondary_predict_dataset.to_dict()\n",
    "\n",
    "# Create a prediction config with the original profile dataset (static) , and a \"new\" transactions prediction dataset\n",
    "\n",
    "predict_config = dr.SecondaryDatasetConfigurations.create(\n",
    "    project_id=project.id,\n",
    "    name=\"Batch Prediction Configuration\",\n",
    "    featurelist_id=model.featurelist_id,\n",
    "    secondary_datasets=[\n",
    "        self_join_secondary_predict_dataset.to_dict(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(deployment_id)\n",
    "data_stores = dr.DataStore.list(typ='all')\n",
    "str_data_stores = [str(data_store) for data_store in data_stores]\n",
    "index = str_data_stores.index(\"DataStore(\\'DR_SAP_TEMPLATES_ALTERNATE\\')\")\n",
    "dsp_data_alternate_store= data_stores[index]\n",
    "creds = dr.Credential.list()\n",
    "str_cred_names = [str(cred.name) for cred in creds]\n",
    "index = str_cred_names.index(\"DR_SAP_TEMPLATE_CRED\")\n",
    "dsp_cred = creds[index]\n",
    "\n",
    "#dataset_id = '674a33ca3e42ee7f62667a8e'\n",
    "#scoring_dataset = dr.Dataset.get(dataset_id)\n",
    "primary_scoring_dataset=dr.Dataset.get(primary_scoring_dataset_id)\n",
    "batch_prediction_job_config={\n",
    "    \"deploymentId\": deployment_id,\n",
    "    \"num_concurrent\": 4,\n",
    "    \"intake_settings\":\n",
    "        {\n",
    "        'type': 'dataset',\n",
    "        'datasetId': primary_scoring_dataset_id, \n",
    "        },\n",
    "    \"passthrough_columns\": \n",
    "        ['CUSTOMER_NUMBER', 'NET_PAYMENT_TERMS_PERIOD', 'Days_Late',\n",
    "        'INVOICE_DUE_DATE', 'ORDER_DATE', 'CASH_DISCOUNT_DAYS_2',\n",
    "        'Invoice_Due_Date_Year_Month', 'STATUS_MANUAL_PRICE_CHANGE',\n",
    "        'INVOICE_NUMBER', 'CASH_DISCOUNT_DAYS_1', 'NET_VALUE_OF_ITEM',\n",
    "        'CASH_DISCOUNT_AMOUNT', 'ITEM_CREDIT_PRICE', 'PAYMENT_TERM',\n",
    "        'MATERIAL_NAME', 'AMT_ELIGIBLE_FOR_CASH_DISCOUNT',\n",
    "        'ITEM_CREDIT_PRICE_ROUNDED', 'BASELINE_DT_FOR_DUE_DATE_CALC',\n",
    "        'MATERIAL_NUMBER', 'CASH_DISCOUNT_PERCENTAGE_2',\n",
    "        'ACTUAL_INVOICED_QUANTITY_CASES', 'Payment_Status',\n",
    "        'INVOICE_TO_PAID_DAYS', 'EXPECTED_AMOUNT', 'CUSTOMER_NAME',\n",
    "        'CASH_DISCOUNT_PERCENTAGE_1', 'SHIP_DATE', 'Days_to_Ship',\n",
    "        'ORDER_TO_PAID_DAYS', 'ACTUAL_PAID_DATE'\n",
    "        ],\n",
    "    \"output_settings\":\n",
    "        {\n",
    "        'type': 'jdbc',\n",
    "        'table': \"PREDICTION_RESULTS_SAP_TEMPLATE_{{ current_run_timestamp }}\",\n",
    "        'schema': 'DR_SAP_TEMPLATES#TEMPLATE_DB_USER', \n",
    "        'statement_type': 'create_table',\n",
    "        'data_store_id': dsp_data_alternate_store.id,\n",
    "        'credential_id': dsp_cred.credential_id,\n",
    "        },\n",
    "}\n",
    "batch_prediction_job_schedule = {\n",
    "    \"day_of_week\": [1],\n",
    "    \"month\": [\"*\"],\n",
    "    \"hour\": [16],\n",
    "    \"minute\": [0],\n",
    "    \"day_of_month\": [1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobotx.idp.batch_predictions import get_update_or_create_batch_prediction_job # type: ignore\n",
    "from infra.settings_main import project_name\n",
    "batch_prediction_job=get_update_or_create_batch_prediction_job(\n",
    "    endpoint=client.endpoint,\n",
    "    token=client.token,\n",
    "    deployment_id=deployment_id,\n",
    "    enabled=True,\n",
    "    name= f\"Recipe Template Batch Prediction [{project_name}]\",\n",
    "    batch_prediction_job=batch_prediction_job_config,\n",
    "    schedule=batch_prediction_job_schedule,\n",
    "    \n",
    ")\n",
    "print(f\"batch_prediction_job: {batch_prediction_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"batch_prediction_job: {batch_prediction_job}\")\n",
    "prediction_job_definition=dr.BatchPredictionJobDefinition.get(batch_prediction_job)\n",
    "job = prediction_job_definition.run_once()\n",
    "job.wait_for_completion()\n",
    "print(f\"Batch prediction job completed with status: {job.status}\")\n",
    "print(f\"Batch predictions written to table: {batch_prediction_job_config['output_settings']['table']}\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
